{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "from darts_pp.search import Searching\n",
    "with fluid.dygraph.guard():\n",
    "    searching = Searching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess\n",
    "preprocess()\n",
    "\n",
    "# pytorch\n",
    "from darts_pt.search import Searching\n",
    "from darts_pt.train import Training\n",
    "from darts_pt.prediction import Prediction\n",
    "s = Searching()\n",
    "s.search()\n",
    "t = Training()\n",
    "t.main_run()\n",
    "p = Prediction()\n",
    "p.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import pdb\n",
    "from darts_pp.ops import *\n",
    "import torch\n",
    "from darts_pp.utils import accuracy\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "\n",
    "def test():\n",
    "#     pdb.set_trace()\n",
    "    y_pred = np.random.rand(2,10)\n",
    "    y = np.random.randint(0,3,(2,))\n",
    "    print(y_pred,y)\n",
    "    yp_t = torch.as_tensor(y_pred, dtype=torch.float)\n",
    "    y_t = torch.as_tensor(y, dtype=torch.long)\n",
    "    lt = torch.nn.CrossEntropyLoss()(yp_t,y_t)\n",
    "    print('torch loss: {}'.format(lt))\n",
    "    print('torch acc: {}'.format(accuracy(yp_t,y_t,topk=(1,5))))\n",
    "    m = torch.nn.Conv2d(2,2,1)\n",
    "#     for i in m.parameters():\n",
    "#         print(i.dtype)\n",
    "    with fluid.dygraph.guard(fluid.CUDAPlace(0)):\n",
    "#         value = np.random.rand(10,2,4,4).astype('float32')\n",
    "        \n",
    "        yp_pp = fluid.dygraph.to_variable(y_pred)\n",
    "        y_pp = fluid.dygraph.to_variable(y[:,np.newaxis])\n",
    "        lpp = fluid.layers.reduce_mean(fluid.layers.softmax_with_cross_entropy(yp_pp, y_pp))\n",
    "        print('pp loss: {}'.format(lpp.numpy()))\n",
    "        print('pp acc: {}'.format([fluid.layers.accuracy(yp_pp, y_pp, k=1).numpy(), \n",
    "                                  fluid.layers.accuracy(yp_pp, y_pp, k=5).numpy()]))\n",
    "        print(sum([lpp,lpp]))\n",
    "        \n",
    "        m = Pool2D(pool_type='avg', global_pooling=True)\n",
    "        print(m(y_pred).shape)\n",
    "#         a = fluid.dygraph.to_variable(value)\n",
    "        \n",
    "#         for i in OPS:\n",
    "#             print(i, OPS[i](2,2,False)(a).shape)\n",
    "        \n",
    "#         alpha = fluid.layers.create_parameter([1], 'float32')\n",
    "\n",
    "#         linear = fluid.Linear(3, 2, dtype=\"float32\")\n",
    "#         for i in linear.parameters():\n",
    "#             print(i.dtype)\n",
    "\n",
    "#         print((list(linear.parameters())))\n",
    "#         adam = fluid.optimizer.Adam(parameter_list=linear.parameters())\n",
    "# #         out = linear(a)\n",
    "#         out = linear(value)\n",
    "#         print(type(linear))\n",
    "#         out.backward()\n",
    "#         adam.minimize(out)\n",
    "#         linear.clear_gradients()\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "from paddle.fluid.initializer import NormalInitializer, MSRAInitializer, ConstantInitializer\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    emb = fluid.dygraph.Embedding(\n",
    "        size=[2, 2],\n",
    "        param_attr='emb.w',\n",
    "        is_sparse=False)\n",
    "    state_dict = emb.state_dict()\n",
    "    print(state_dict)\n",
    "    fluid.save_dygraph(state_dict, \"paddle_dy\")  # 会保存为 paddle_dy.pdparams\n",
    "\n",
    "    adam = fluid.optimizer.Adam(\n",
    "#         learning_rate=0.001,\n",
    "        parameter_list = emb.parameters())\n",
    "    state_dict = adam.state_dict()\n",
    "    adam._learning_rate=0.2\n",
    "    print(adam.current_step_lr())\n",
    "#     fluid.save_dygraph(state_dict, \"paddle_dy\")  # 会保存为 paddle_dy.pdopt\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    emb2 = fluid.dygraph.Embedding(\n",
    "        size=[2, 2],\n",
    "        param_attr='emb.w',\n",
    "        is_sparse=False)\n",
    "    state_dict = emb2.state_dict()\n",
    "    print(state_dict)\n",
    "    model_states,_ = fluid.load_dygraph('paddle_dy')\n",
    "    print(model_states)\n",
    "    emb2.set_dict(model_states)\n",
    "    print(emb2.state_dict())\n",
    "    ma = fluid.dygraph.nn.BatchNorm(3)\n",
    "    mb = fluid.dygraph.nn.BatchNorm(\n",
    "                num_channels=3,\n",
    "                param_attr=fluid.ParamAttr(\n",
    "                    initializer=ConstantInitializer(value=1),trainable=False),\n",
    "                bias_attr=fluid.ParamAttr(\n",
    "                    initializer=ConstantInitializer(value=0),trainable=False))\n",
    "    for i in ma.parameters():\n",
    "        print(i)\n",
    "    print('--------------------')\n",
    "    for i in mb.parameters():\n",
    "        print(i)\n",
    "\n",
    "# print(adam.current_step_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fluid.dygraph.LayerList()\n",
    "a.append(fluid.dygraph.nn.Linear(1,1))\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "ParamAttr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "import numpy as np\n",
    "from torch.functional import F\n",
    "import torch\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "#     data = np.random.random((3, 1,32, 32)).astype('float32')\n",
    "    \n",
    "# #     pool2d = fluid.dygraph.Pool2D(pool_size=2,\n",
    "# #                   pool_type='max',\n",
    "# #                   pool_stride=1,\n",
    "# #                   global_pooling=False)\n",
    "#     pool2d = fluid.dygraph.Pool2D(pool_type='avg', global_pooling=True)\n",
    "#     pool2d_res = pool2d(to_variable(data))\n",
    "#     print(pool2d_res.shape)\n",
    "    \n",
    "    x = np.random.rand(2,3)\n",
    "    print(x)\n",
    "    tx = torch.as_tensor(x)\n",
    "    print(F.softmax(tx,dim=0))\n",
    "    print(F.softmax(tx,dim=-1))\n",
    "    print(fluid.layers.softmax(to_variable(x)).detach().numpy())\n",
    "    print(fluid.layers.softmax(to_variable(x)).detach())\n",
    "    print(fluid.layers.softmax(to_variable(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluid.layers.softmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
