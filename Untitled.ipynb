{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess\n",
    "from search import Searching\n",
    "from train import Training\n",
    "# preprocess()\n",
    "# s = Searching()\n",
    "# s.search()\n",
    "t = Training()\n",
    "t.main_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pdb\n",
    "from torch.autograd import Variable\n",
    "def drop_path(x, drop_prob):\n",
    "#     pdb.set_trace()\n",
    "    if drop_prob > 0.:\n",
    "        keep_prob = 1.-drop_prob\n",
    "        mask = torch.zeros(1,x.size(1)).bernoulli_(keep_prob)\n",
    "        x /= keep_prob\n",
    "        x *= mask\n",
    "    return x\n",
    "torch.manual_seed(0)\n",
    "x = torch.rand(3,3)\n",
    "# print(drop_path(x, 0))\n",
    "m = torch.nn.Dropout2d(1)\n",
    "print(list(m.parameters()))\n",
    "m.eval()\n",
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('log/best_genotype.pkl','rb') as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pipeline import Dataset\n",
    "from tqdm import tqdm\n",
    "dataset = Dataset()\n",
    "tg = dataset.train_generator\n",
    "vg = dataset.val_generator\n",
    "with tqdm(tg.epoch(), total = tg.spe, desc = 'debug') as pbar:\n",
    "    for step, (x, y) in enumerate(pbar):\n",
    "        print(x.shape)\n",
    "        break\n",
    "        pass\n",
    "# with tqdm(vg.epoch(), total = vg.spe, desc = 'debug') as pbar:\n",
    "#     for step, (x, y) in enumerate(pbar):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv['train_0' if False else 'val_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import load_fmnist\n",
    "x,y = load_fmnist('data/fmnist/')\n",
    "_, axs = plt.subplots(1,10,figsize=(40,5))\n",
    "for i in range(10):\n",
    "    axs[i].imshow(x[i].reshape(28,28))\n",
    "    print(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axs = plt.subplots(1,3,figsize=(30,10))\n",
    "axs[0].hist(x_train.flatten())\n",
    "zscored = (x_train-np.mean(x_train))/(np.std(x_train)+1e-10)\n",
    "axs[1].hist(zscored.flatten())\n",
    "minmaxed = (zscored - np.min(zscored,axis=(-1,-2)).reshape(-1,1,1))/(np.max(zscored,axis=(-1,-2)).reshape(-1,1,1)-np.min(zscored,axis=(-1,-2)).reshape(-1,1,1))\n",
    "axs[2].hist(minmaxed.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(10,size=(2,3,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a - np.min(a,axis=(-1,-2)).reshape(-1,1,1))/(np.max(a,axis=(-1,-2)) - np.min(a,axis=(-1,-2))).reshape(-1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.max(a,axis=(-1,-2)) - np.min(a,axis=(-1,-2))).reshape(-1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:'adsf',2:'sdf',30:34, 4:4}\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(zscored,axis=(-1,-2)).reshape(-1,1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from .base import BaseDataset\n",
    "import pydicom\n",
    "from util.augmentations import *\n",
    "from util.utils import create_class_weight\n",
    "import pdb\n",
    "import glob\n",
    "\n",
    "def make_dataset(root, dirname, type='CT', is_dup=False):\n",
    "#     pdb.set_trace()\n",
    "    base_path = os.path.join(root, dirname)\n",
    "    images_path = os.path.join(root, dirname, 'DICOM_anon', 'InPhase' if is_dup else '')\n",
    "    mask_path = os.path.join(root, dirname, 'Ground')\n",
    "\n",
    "    images = sorted(glob.glob(os.path.abspath(images_path+'/*')))\n",
    "    truth = sorted(glob.glob(os.path.abspath(mask_path+'/*')))\n",
    "    images_list = [(i,j) for i,j in zip(images,truth)]\n",
    "#     for image_name in images:\n",
    "#         if type == 'CT': # two types batch\n",
    "#             if 'IMG' in image_name:\n",
    "#                 image_mask_name = 'liver_GT_' + image_name[:-4].split('-')[-1][2:] + '.png'\n",
    "#             else:\n",
    "#                 image_mask_name = 'liver_GT_' + image_name[:-4].split(',')[0][2:] + '.png'\n",
    "#         else:\n",
    "#             M = image_name[:-4].split('-')[-1]\n",
    "#             id = \"%03d\" % ((int(M)+1) // 2) if is_dup else M[2:]\n",
    "#             image_mask_name = 'liver_' + id + '.png'\n",
    "#         img_path = os.path.join(images_path, image_name)\n",
    "#         img_mask_path = os.path.join(mask_path, image_mask_name)\n",
    "#         images_list.append((img_path, img_mask_path))\n",
    "\n",
    "    return images_list\n",
    "\n",
    "def histogram(image):\n",
    "    hist = dict()\n",
    "\n",
    "    # Initialize dict\n",
    "    for shade in range(0, 256):\n",
    "        hist[shade] = 0\n",
    "\n",
    "    for index, val in np.ndenumerate(image):\n",
    "        hist[val] += 1\n",
    "\n",
    "    return hist\n",
    "\n",
    "def shade_at_percentile(hist, percentile):\n",
    "    n = sum(hist.values())\n",
    "    cumulative_sum = 0.0\n",
    "    for shade in range(0, 256):\n",
    "        cumulative_sum += hist[shade]\n",
    "        if cumulative_sum / n >= percentile:\n",
    "            return shade\n",
    "\n",
    "    return None\n",
    "\n",
    "def auto_contrast(image):\n",
    "    \"\"\" Apply auto contrast to an image using\n",
    "        https://stackoverflow.com/questions/9744255/instagram-lux-effect/9761841#9761841\n",
    "    \"\"\"\n",
    "    hist = histogram(image)\n",
    "    p5 = shade_at_percentile(hist, .01)\n",
    "    p95 = shade_at_percentile(hist, .99)\n",
    "    a = 255.0 / (p95 + p5)\n",
    "    b = -1.0 * a * p5\n",
    "\n",
    "    result = (image.astype(float) * a) + b\n",
    "    result = result.clip(0, 255.0)\n",
    "\n",
    "    return image\n",
    "\n",
    "def extract_grayscale_image(dicom_data):\n",
    "    # Extracting data from the mri file\n",
    "    plan = dicom_data\n",
    "    shape = plan.pixel_array.shape\n",
    "    # Convert to float to avoid overflow or underflow losses.\n",
    "    image_2d = plan.pixel_array.astype(float)\n",
    "\n",
    "    # Rescaling grey scale between 0-255\n",
    "    image_2d_scaled = (np.maximum(image_2d, 0) / image_2d.max()) * 255.0\n",
    "\n",
    "    # Convert to uint\n",
    "    image_2d_scaled = np.uint8(image_2d_scaled)\n",
    "\n",
    "    return image_2d_scaled\n",
    "\n",
    "\n",
    "class CHAOS(BaseDataset):\n",
    "#     TYPE = 'CT'\n",
    "    TYPE = 'MR'\n",
    "    BASE_DIR, NUM_CLASS, CROP_SIZE = ('CHAOS/CT_data/', 2, 256) if TYPE=='CT'\\\n",
    "        else ('CHAOS/MR_data/', 5, 256)\n",
    "    IN_CHANNELS = 1\n",
    "    CLASS_WEIGHTS = None\n",
    "    mean = [0.2389]\n",
    "    std = [0.2801]\n",
    "    def __init__(self, root,  split='train', mode=None):\n",
    "        super(CHAOS, self).__init__(root, split, mode, norm = {'mu': self.mean, 'std': self.std})\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.joint_transform = None\n",
    "        # The MR image is too challenge!\n",
    "        self.joint_transform = Compose([\n",
    "            RandomTranslate(offset=(0.3, 0.3)),\n",
    "            RandomVerticallyFlip(),\n",
    "            RandomHorizontallyFlip(),\n",
    "            RandomElasticTransform(alpha=1.5, sigma=0.07),\n",
    "        ])\n",
    "        base_path = os.path.join(self.root, self.BASE_DIR)\n",
    "        self.data_info = []\n",
    "\n",
    "        if mode in ['train', 'val']:\n",
    "            dirnames = os.listdir(base_path)\n",
    "            if self.TYPE == 'MR':\n",
    "                for dir in dirnames:\n",
    "                    if dir == 'notes.txt':\n",
    "                        continue\n",
    "                    self.data_info += make_dataset(base_path, dir + '/T1DUAL', type='MR', is_dup=True)\n",
    "                    self.data_info += make_dataset(base_path, dir + '/T2SPIR', type='MR')\n",
    "            else:\n",
    "                for dir in dirnames:\n",
    "                    if dir == 'notes.txt':\n",
    "                        continue\n",
    "                    self.data_info += make_dataset(base_path, dir)\n",
    "\n",
    "            if len(self.data_info) == 0:\n",
    "                raise (RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                \"Supported image extensions are: \" + \",\".join('png')))\n",
    "        else:\n",
    "            self.data_info = []\n",
    "#         pdb.set_trace()\n",
    "        if self.TYPE == 'MR':\n",
    "            self.CLASS_WEIGHTS = torch.tensor(self._generate_weight())\n",
    "\n",
    "    def _generate_weight(self):\n",
    "        weight_dict = {0:0., 80:0., 160:0., 240:0, 255:0.}\n",
    "        areas = 256.*256.\n",
    "#         pdb.set_trace()\n",
    "        for index in range(len(self.data_info)):\n",
    "            img_path, target_path = self.data_info[index][0], self.data_info[index][1]\n",
    "            try:\n",
    "                target = Image.open(target_path).convert('L')\n",
    "            except:\n",
    "                print(target_path)\n",
    "            target_np = np.array(target)\n",
    "            unique, counts = np.unique(target_np, return_counts=True)\n",
    "            dict_c = dict(zip(unique, counts))\n",
    "            for id, val in dict_c.items():\n",
    "                try:\n",
    "                    weight_dict[id] += val / areas\n",
    "                except KeyError:\n",
    "                    weight_dict[id] = val/areas\n",
    "#         pdb.set_trace()\n",
    "        weight_list = [weight_dict[k] for k in sorted(weight_dict.keys())]\n",
    "        return create_class_weight(weight_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if len(self.data_info) == 0:\n",
    "            return None, None\n",
    "\n",
    "        img_path, target_path = self.data_info[index][0], self.data_info[index][1]\n",
    "\n",
    "        # Read image\n",
    "        dataset = pydicom.dcmread(img_path)\n",
    "        target = Image.open(target_path).convert('L')\n",
    "        if 'PixelData' in dataset:\n",
    "            if dataset.Modality == \"CT\":  # size: 512x512\n",
    "                img, itercept = dataset.RescaleSlope * dataset.pixel_array + dataset.RescaleIntercept, dataset.RescaleIntercept\n",
    "                img[img >= 4000] = itercept  # remove abnormal pixel\n",
    "            else:  # size: 256x256\n",
    "                img = extract_grayscale_image(dataset)\n",
    "                img = auto_contrast(img)\n",
    "\n",
    "            img = Image.fromarray(img).convert('L')\n",
    "\n",
    "        # 1. do crop transform\n",
    "        if self.mode == 'train':\n",
    "            img, target = self.random_crop(img, target)\n",
    "        elif self.mode == 'val':\n",
    "            img, target = self.random_center_crop(img, target)\n",
    "\n",
    "        # 2. do joint transform\n",
    "        if self.joint_transform is not None:\n",
    "            img, target = self.joint_transform(img, target)\n",
    "\n",
    "        ## 3.to tensor\n",
    "        img, target = self.to_tensor(img, target)\n",
    "\n",
    "        # 4. normalize for img\n",
    "        img = self.img_normalize(img)\n",
    "\n",
    "        if self.TYPE == 'CT':\n",
    "            # Convert label to 0, 1\n",
    "            target[target == 255] = 1\n",
    "        else:\n",
    "            target[target == 80] = 1\n",
    "            target[target == 160] = 2\n",
    "            target[target == 240] = 3\n",
    "            target[target == 255] = 4\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
