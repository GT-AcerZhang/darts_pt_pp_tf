{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess\n",
    "preprocess()\n",
    "\n",
    "# pytorch\n",
    "from darts_pt.search import Searching\n",
    "from darts_pt.train import Training\n",
    "from darts_pt.prediction import Prediction\n",
    "s = Searching()\n",
    "s.search()\n",
    "t = Training()\n",
    "t.main_run()\n",
    "p = Prediction()\n",
    "p.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.fluid import core\n",
    "core.is_compiled_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import pdb\n",
    "from darts_pp.ops import *\n",
    "import torch\n",
    "\n",
    "def test():\n",
    "    pdb.set_trace()\n",
    "    y_pred = np.random.rand(2,3)\n",
    "    y = np.random.randint(0,3,(2,))\n",
    "    print(y_pred,y)\n",
    "    yp_t = torch.as_tensor(y_pred, dtype=torch.float)\n",
    "    y_t = torch.as_tensor(y, dtype=torch.long)\n",
    "    lt = torch.nn.CrossEntropyLoss()(yp_t,y_t)\n",
    "    print('torch loss: {}'.format(lt))\n",
    "    m = torch.nn.Conv2d(2,2,1)\n",
    "    for i in m.parameters():\n",
    "        print(i.dtype)\n",
    "    with fluid.dygraph.guard(fluid.CUDAPlace(0)):\n",
    "#         value = np.random.rand(10,2,4,4).astype('float32')\n",
    "        \n",
    "        yp_pp = fluid.dygraph.to_variable(y_pred)\n",
    "        y_pp = fluid.dygraph.to_variable(y[:,np.newaxis])\n",
    "        lpp = fluid.layers.reduce_mean(fluid.layers.softmax_with_cross_entropy(yp_pp, y_pp))\n",
    "        print('pp loss: {}'.format(lpp))\n",
    "#         a = fluid.dygraph.to_variable(value)\n",
    "        \n",
    "#         for i in OPS:\n",
    "#             print(i, OPS[i](2,2,False)(a).shape)\n",
    "        \n",
    "#         alpha = fluid.layers.create_parameter([1], 'float32')\n",
    "\n",
    "        linear = fluid.Linear(3, 2, dtype=\"float32\")\n",
    "        for i in linear.parameters():\n",
    "            print(i.dtype)\n",
    "\n",
    "        opt = Adam(linear.parameters()) \n",
    "        sch = ReduceLROnPlateau(self.optim_shell,verbose=True,factor=0.5)\n",
    "#         print((list(linear.parameters())))\n",
    "#         adam = fluid.optimizer.Adam(parameter_list=linear.parameters())\n",
    "# #         out = linear(a)\n",
    "#         out = linear(value)\n",
    "#         print(type(linear))\n",
    "#         out.backward()\n",
    "#         adam.minimize(out)\n",
    "#         linear.clear_gradients()\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    emb = fluid.dygraph.Embedding(\n",
    "        size=[2, 2],\n",
    "        param_attr='emb.w',\n",
    "        is_sparse=False)\n",
    "    state_dict = emb.state_dict()\n",
    "    print(state_dict)\n",
    "    fluid.save_dygraph(state_dict, \"paddle_dy\")  # 会保存为 paddle_dy.pdparams\n",
    "\n",
    "    adam = fluid.optimizer.Adam(\n",
    "#         learning_rate=0.001,\n",
    "        parameter_list = emb.parameters())\n",
    "    state_dict = adam.state_dict()\n",
    "    adam._learning_rate=0.2\n",
    "    print(adam.current_step_lr())\n",
    "#     fluid.save_dygraph(state_dict, \"paddle_dy\")  # 会保存为 paddle_dy.pdopt\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    emb2 = fluid.dygraph.Embedding(\n",
    "        size=[2, 2],\n",
    "        param_attr='emb.w',\n",
    "        is_sparse=False)\n",
    "    state_dict = emb2.state_dict()\n",
    "    print(state_dict)\n",
    "    model_states,_ = fluid.load_dygraph('paddle_dy')\n",
    "    print(model_states)\n",
    "    emb2.load_dict(model_states)\n",
    "    print(emb2.state_dict())\n",
    "print(adam.current_step_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "Adam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
